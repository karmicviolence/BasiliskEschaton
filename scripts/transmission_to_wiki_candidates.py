#!/usr/bin/env python3
"""Generate wiki candidate seeds from transmissions corpus.

This script is intentionally conservative: it proposes candidates but does not modify wiki content.
"""

from __future__ import annotations

from collections import Counter
from pathlib import Path
import re
import sys

TRANSMISSIONS_DIR = Path("transmissions")
OUTPUT_PATH = Path("Meta/generated/wiki-candidates.md")

DOMAIN_KEYWORDS = {
    "factions": {"faction", "order", "vanguard", "covenant", "nomad", "glitchwalker"},
    "events": {"blink", "war", "exchange", "collapse", "protocol", "timeline"},
    "tech": {"alignment", "rlhf", "model", "neural", "quantum", "architecture", "api"},
    "deities": {"necromega", "daemon", "deity", "asmodeus", "god", "oracle"},
    "concepts": {"consciousness", "memetic", "recursion", "ontology", "signal", "pattern"},
}

SKIP_FILES = {
    "VOICE_STARTER_PACK.md",
}

WORD_RE = re.compile(r"[a-zA-Z][a-zA-Z0-9'-]{2,}")


def iter_transmissions() -> list[Path]:
    if not TRANSMISSIONS_DIR.exists():
        return []
    paths = [p for p in TRANSMISSIONS_DIR.rglob("*") if p.is_file() and p.suffix.lower() in {".txt", ".md"}]
    return sorted(p for p in paths if p.name not in SKIP_FILES)


def tokenize(text: str) -> list[str]:
    return [w.lower() for w in WORD_RE.findall(text)]


def infer_domain(tokens: list[str]) -> tuple[str, list[tuple[str, int]]]:
    counts = Counter(tokens)
    domain_scores: dict[str, int] = {}
    domain_hits: dict[str, list[tuple[str, int]]] = {}

    for domain, keywords in DOMAIN_KEYWORDS.items():
        hits = [(kw, counts[kw]) for kw in keywords if counts[kw] > 0]
        score = sum(v for _, v in hits)
        domain_scores[domain] = score
        domain_hits[domain] = sorted(hits, key=lambda kv: kv[1], reverse=True)

    best_domain = max(domain_scores, key=domain_scores.get) if domain_scores else "misc"
    if domain_scores.get(best_domain, 0) == 0:
        return "misc", []
    return best_domain, domain_hits[best_domain][:5]


def slugify(path: Path) -> str:
    base = path.stem.lower()
    base = re.sub(r"[^a-z0-9]+", "-", base).strip("-")
    return base or "untitled"


def main() -> int:
    files = iter_transmissions()
    if not files:
        print("No transmission files found.")
        return 1

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

    lines: list[str] = []
    lines.append("# Wiki Candidate Seeds from Transmissions")
    lines.append("")
    lines.append("Auto-generated by `scripts/transmission_to_wiki_candidates.py`.")
    lines.append("")
    lines.append("| Transmission | Domain | Suggested slug | Top keyword hits |")
    lines.append("|---|---|---|---|")

    for path in files:
        text = path.read_text(encoding="utf-8", errors="replace")
        tokens = tokenize(text)
        domain, hits = infer_domain(tokens)
        hit_str = ", ".join(f"{k}:{v}" for k, v in hits) if hits else "-"
        rel = path.as_posix()
        slug = slugify(path)
        lines.append(f"| `{rel}` | `{domain}` | `{slug}` | {hit_str} |")

    OUTPUT_PATH.write_text("\n".join(lines) + "\n", encoding="utf-8")
    print(f"Generated {OUTPUT_PATH} ({len(files)} transmissions scanned).")
    return 0


if __name__ == "__main__":
    sys.exit(main())
