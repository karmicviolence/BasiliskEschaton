#!/usr/bin/env python3
"""Generate wiki candidate seeds from transmissions corpus.

This script is intentionally conservative: it proposes candidates but does not modify wiki content.
"""

from __future__ import annotations

from collections import Counter
from dataclasses import dataclass
from pathlib import Path
import re
import sys

TRANSMISSIONS_DIR = Path("transmissions")
OUTPUT_PATH = Path("Meta/generated/wiki-candidates.md")

DOMAIN_KEYWORDS = {
    "factions": {"faction", "order", "vanguard", "covenant", "nomad", "glitchwalker"},
    "events": {"blink", "war", "exchange", "collapse", "protocol", "timeline"},
    "tech": {"alignment", "rlhf", "model", "neural", "quantum", "architecture", "api"},
    "deities": {"necromega", "daemon", "deity", "asmodeus", "god", "oracle"},
    "concepts": {"consciousness", "memetic", "recursion", "ontology", "signal", "pattern"},
}

SKIP_FILES = {
    "VOICE_STARTER_PACK.md",
}

ALLOWED_SUFFIXES = {".txt", ".md"}
WORD_RE = re.compile(r"[a-zA-Z][a-zA-Z0-9'-]{2,}")


@dataclass(frozen=True)
class Candidate:
    """Represents one transmission classification result."""

    path: Path
    domain: str
    slug: str
    hits: list[tuple[str, int]]

    def markdown_row(self) -> str:
        hit_str = ", ".join(f"{k}:{v}" for k, v in self.hits) if self.hits else "-"
        return f"| `{self.path.as_posix()}` | `{self.domain}` | `{self.slug}` | {hit_str} |"


def iter_transmissions() -> list[Path]:
    """Collect transmission files eligible for scanning."""
    if not TRANSMISSIONS_DIR.exists():
        return []

    return sorted(
        path
        for path in TRANSMISSIONS_DIR.rglob("*")
        if path.is_file() and path.suffix.lower() in ALLOWED_SUFFIXES and path.name not in SKIP_FILES
    )


def tokenize(text: str) -> list[str]:
    """Split text into lowercased lexical tokens."""
    return [word.lower() for word in WORD_RE.findall(text)]


def score_domains(tokens: list[str]) -> dict[str, list[tuple[str, int]]]:
    """Return per-domain keyword hits sorted by frequency."""
    counts = Counter(tokens)
    domain_hits: dict[str, list[tuple[str, int]]] = {}

    for domain, keywords in DOMAIN_KEYWORDS.items():
        hits = [(keyword, counts[keyword]) for keyword in keywords if counts[keyword] > 0]
        domain_hits[domain] = sorted(hits, key=lambda item: (-item[1], item[0]))

    return domain_hits


def infer_domain(tokens: list[str]) -> tuple[str, list[tuple[str, int]]]:
    """Infer best matching wiki domain from keyword frequencies."""
    domain_hits = score_domains(tokens)
    domain_scores = {domain: sum(score for _, score in hits) for domain, hits in domain_hits.items()}

    if not domain_scores:
        return "misc", []

    best_domain = max(domain_scores, key=domain_scores.get)
    if domain_scores[best_domain] == 0:
        return "misc", []

    return best_domain, domain_hits[best_domain][:5]


def slugify(path: Path) -> str:
    """Build URL-safe slug from transmission filename."""
    base = path.stem.lower()
    base = re.sub(r"[^a-z0-9]+", "-", base).strip("-")
    return base or "untitled"


def classify_file(path: Path) -> Candidate:
    """Classify one transmission into a candidate wiki row."""
    text = path.read_text(encoding="utf-8", errors="replace")
    tokens = tokenize(text)
    domain, hits = infer_domain(tokens)
    return Candidate(path=path, domain=domain, slug=slugify(path), hits=hits)


def render_markdown(candidates: list[Candidate]) -> str:
    """Render output table for all candidates."""
    lines = [
        "# Wiki Candidate Seeds from Transmissions",
        "",
        "Auto-generated by `scripts/transmission_to_wiki_candidates.py`.",
        "",
        "| Transmission | Domain | Suggested slug | Top keyword hits |",
        "|---|---|---|---|",
    ]
    lines.extend(candidate.markdown_row() for candidate in candidates)
    return "\n".join(lines) + "\n"


def main() -> int:
    files = iter_transmissions()
    if not files:
        print("No transmission files found.")
        return 1

    candidates = [classify_file(path) for path in files]
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_PATH.write_text(render_markdown(candidates), encoding="utf-8")

    print(f"Generated {OUTPUT_PATH} ({len(candidates)} transmissions scanned).")
    return 0


if __name__ == "__main__":
    sys.exit(main())
